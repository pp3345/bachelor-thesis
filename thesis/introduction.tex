\chapter{Introduction}
\label{sec:introduction}

Vector instruction sets enable software developers to execute the same operation on multiple data in parallel and allow for fast and energy-efficient implementations in microprocessors as fewer clock cycles and fewer instructions (thus, less pipeline overhead) are required to achieve equal results compared to a purely scalar instruction set where each operation is only applied to a single datum. Traditionally, 3D graphics processing is a typical use case for vector instructions -- large amounts of polygons need to be processed and transformed using the very same calculations, therefore it makes sense to design instruction sets that are inherently parallel for this purpose. This is why graphics processors (\glspl{GPU}) were invented in the first place: these chips are specifically designed for vector processing and are thus also categorized as \textit{\acrlong{SIMD}} ({\acrshort{SIMD}\glsunset{SIMD}) processors. However, other use cases exist where vector instructions seem useful but do not justify the use of a specialized processor. For example, some cryptographic algorithms or multi-media codecs may be accelerated through vector execution but are typically not run long enough or do not expose the massive parallelism of applications like 3D graphics, hence, to some extent, it is desirable to include vector processing functionality in general-purpose processors.

With the advent of the \gls{MMX} in the \textit{Pentium MMX} processor in 1997, Intel was the first vendor to introduce an \gls{SIMD} extension to processors based on the \gls{x86} instruction set architecture \cite{intelmmx}. However, due to rapidly increasing computational demands, \gls{MMX} was quickly superseded by the \gls{SSE} that added support for \SI{128}{\bit} vector registers and debuted with the \textit{Intel Pentium III} processor in 1999 \cite{intelsse}. Many iterations of \gls{SSE} led up to SSE4, which finally evolved into the \gls{AVX} that introduced \SI{256}{\bit} vectors and that constitute the topic of this thesis. After the first release of \gls{AVX} in Intel's \textit{Sandy Bridge} microarchitecture in 2011 \cite{intelsandybridge}, Intel quickly published several improvements in the years to come: \gls{AVX2} with many new instructions was introduced with the \textit{Haswell} microarchitecture in 2013 \cite{hammarlund2014haswell}, and finally, Intel's \textit{Skylake (Server)} microarchitecture in 2017 came with support for \gls{AVX-512}, which added \SI{512}{\bit}-wide vector registers and several new instructions \cite{intelxeonscalabledeepdive}. Notably, there is also a client variant of the \textit{Skylake} microarchitecture that does not feature \gls{AVX-512}. However, \gls{AVX-512} is set to be made available to the broad consumer market with the arrival of the \textit{Icelake} microarchitecture towards the end of 2019 \cite{thicelake}.

For many decades, \emph{\gls{moore}} \cite{moore1975progress} and \emph{\gls{dennard}} \cite{dennard1974design} have guided the development of microprocessors: the first states that, with evolving process technology, the integration density (i.e., the amount of transistors per area) doubles about every two years. The latter declares that, as transistors become smaller, their voltage and current requirements scale proportionally with the reduction in size, and thus the power density stays constant over time. In the recent years, however, development has slowed down as we have nearly reached the physical limitations of what is theoretically possible with silicon. In turn, both of the scaling laws that used to be vital for processor evolution have nearly ended and power density is rising in current generations. This has the effect that it is generally not possible anymore for all transistors within a single chip to switch at full frequency due to arising electrical and thermal issues \cite{taylor2012dark}. The amount of transistors that may run at their maximum frequency is, of course, not only limited for a complete chip but also for any given area within it. As such, the new capabilities of current \gls{AVX} implementations come at a cost: since an arithmetic unit designed for \gls{AVX} needs to have many adjacent data paths within a comparatively small area, processors supporting \gls{AVX2} and \gls{AVX-512} commonly need to reduce their clock frequency when executing such instructions in order to maintain stability.

Reducing the frequency while executing \gls{AVX} code, however, also means that other instructions executed on the same core will run with a lower frequency, too. Further, since frequency switches need some time and therefore come at a slight cost, they should not be done more often than necessary. Consequently, current Intel processors will operate at a reduced frequency for a while even after the last \gls{AVX} instruction has been executed. For heterogeneous workloads that consist of both vector and scalar parts, it was shown that this behavior can have a severe negative impact on a program's overall performance. Using \emph{nginx}, a wide-spread web server software, with a vectorized implementation of the \textit{ChaCha20-Poly1305} algorithm used for encrypting network traffic, \citeauthor{gottschlag19sfma} \cite{gottschlag19sfma} have measured an \SI{11.2}{\percent} reduction in throughput when using \gls{AVX-512} compared to an implementation with \glslink{SSE}{SSE4}. To mitigate the negative effects, they propose \emph{core specialization} as a technique that migrates programs to specific cores when executing \gls{AVX} code and back again when they are in a phase with purely scalar instructions. This way, only a few cores of a processor are affected by \gls{AVX}-induced frequency reduction which, in the case of nginx, yields a vast improvement but does not fully alleviate the performance drawback.

In this thesis, we want to look at a different optimization approach: instead of moving workloads between cores, we want to explore possibilities of improving the reclocking algorithm itself. However, Intel only provides a very vague description of what they have precisely implemented in their chips. For this reason, our work began with conducting an analysis of the implementation in a current-generation Intel processor. Using the \gls{PMU} of such a processor, we measured the amount of instructions required to trigger frequency reductions as well as the delays incurred by them, and how long it takes until the clock speed is raised again. We prove that Intel's claims are not only vague, but also wrong in terms of declared delays and we will provide a more thorough model of the algorithm. Further, as we are unable to modify the hardware itself, we will describe \textsc{avxfreq}, a reimplementation of Intel's \gls{AVX} reclocking behavior through software means, again by using the \gls{PMU} to generate interrupts upon events that indicate a situation where frequency changes may be required. \textsc{avxfreq} is designed to be able to act as a foundation for devising, implementing and evaluating alternative algorithms that potentially improve performance through more intelligent reclocking that allows scalar phases in a program to be executed at a higher clock frequency compared to Intel's implementation. We show that \textsc{avxfreq} is capable of reflecting a simplified model of the hardware algorithm with a performance decrease of about \SI{1}{\percent}. To evaluate the potential of our approach, we will present a reclocking strategy based on \textsc{avxfreq} where we leverage the user-space program's knowledge about what it is going to do next to select the frequency to apply to the processor. For this implementation, we show that it can yield improved performance for heterogeneous workloads by achieving up to \SI{15}{\percent} higher throughput during a purely scalar phase immediately following an \gls{AVX} phase. Another, more automatic optimization idea that may be implemented atop \textsc{avxfreq} is to have the operating system measure vector and scalar execution phases of a process and provide predictions of how long a scalar phase will last. This may be done as future work.

We start by introducing the original problem as well as previous work on the topic in a deeper and more thorough fashion in \Cref{sec:background}. As our analysis of Intel's implementation is a required prerequisite for a software reimplementation, \Cref{sec:analysis} describes the design and implementation of the analysis framework we built and presents the results. Guided by the obtained knowledge, we will detail the design of \textsc{avxfreq} and the user-space-driven reclocking approach outlined above in \Cref{sec:design}. Afterwards, in \Cref{sec:evaluation}, we evaluate how well \textsc{avxfreq} fulfills its purpose and what improvements are achieved when user-space can exercise control over \gls{AVX} reclocking. We conclude this work in \Cref{sec:conclusion} and propose ideas for further research based on our findings.