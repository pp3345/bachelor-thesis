\chapter{Background \& Related Work}
\label{sec:background}

In this thesis, we present an analysis of the reclocking behavior of a current-generation Intel processor when executing \gls{AVX} instructions. We then use the information obtained from the results of this analysis to build a software prototype that tries to accurately reimplement a subset of the algorithm employed by Intel. This reimplementation is designed to constitute a foundation for exploring possible optimizations to the algorithm that yield a better performance in heterogeneous workloads. In this chapter, we will provide an extensive motivation for our work, describe the technologies we built upon, talk about previous and related work, and explain what precisely we are trying to achieve.

\section{Motivation}
\label{sec:background:motivation}

In 1975, Gordon Moore, one of the co-founders of Intel, predicted that the transistor density of integrated circuits made of silicon would double roughly every two years \cite{moore1975progress}. Known today as \emph{\gls{moore}}, his prediction held true for several decades with surprising accuracy. However, like every technology, the advancement of silicon-based microprocessors is confined to physical limitations. About thirty years after his famous prophecy, in 2007, Moore projected his law to only have about 10 to 15 years left \cite{moore2007interview}. And again, he was right: the \SI{14}{\nano\meter} process technology Intel used in 2014 yielded an integration density of about 37.5 million transistors per \si{\milli\meter\squared}, whereas Intel's current \SI{10}{\nano\meter} fabrication node from 2018 allows for around 100.8 million transistors within the same area. This means that, over four years, the density has increased only by a factor of 2.688$\times$, whereas -- according to \gls{moore} -- it should have been 4$\times$ \cite{courtland2017intel}.

The second large scaling law of microelectronics is known as \emph{\gls{dennard}} or \emph{Dennardian Scaling} and is named after Robert H. Dennard who is one of the authors of a historically important paper from 1974 on the design of very small \glspl{MOSFET} \cite{dennard1974design}. In their work, \citeauthor{dennard1974design} have shown that when a silicon \gls{MOSFET} is scaled down by a factor $\kappa$, its voltage and current requirements decline proportionally with $\kappa$. In turn, this means that as smaller \glspl{MOSFET} can be manufactured with evolving chemical process technology, their power density stays constant, or in other words: as manufacturing possibilities advance, chips of the same total area can be produced with smaller and more transistors and no increases in power density. Similar to \gls{moore}, \gls{dennard} has come to an end in recent years: in the 1970s, current leakage only had very small and negligible impact on a chip's power consumption and was therefore not considered as a component in Dennard's formulas \cite{bohr200730}. However, today a point is reached in the scaling of \glspl{MOSFET} where switching current and threshold voltage are low enough that leakage has become a major source of energy usage in microprocessors, causing increasing power densities and the breakdown of Dennardian scaling.

These scaling laws used to be essential for the advancement of microprocessors as they guaranteed the ability to build more complex and at the same time energy-saving designs over the years. Now, due to the shifted conditions, creativity is required from engineers to come up with new ways of improving both power consumption and performance of processors. One approach that has been proposed is the use of \emph{dark silicon} and \emph{dim silicon} \cite{huang2011scaling}: given that, due to increased power density, it is not possible anymore for all transistors in a processor to switch at their maximum frequency at the same time, dim silicon was coined as a term for a technique where specific parts operate at a lower frequency than others. Dark silicon further refers to parts of a chip that remain turned off most of the time.

In current Intel x86 processors, we can find a dim silicon approach in their implementation of the \gls{AVX} instruction set extension: as these instructions cause higher energy consumption than previous vector instruction sets or scalar instructions, they may not be executed at full frequency or otherwise system stability would be at risk due to exceeded electrical and thermal limits. In turn, whenever a core of these processors is fed with demanding \gls{AVX} instructions, it will reduce its clock frequency. From this moment on, everything executed on that specific core runs slower, allowing \gls{AVX} instructions to run, but at the cost of reduced performance for other operations. However, frequency changes need some time: \citeauthor{mazouz2014evaluation} \cite{mazouz2014evaluation} have shown them to take between \SI{25}{\micro\second} and \SI{52}{\micro\second} on an Intel Core i7-3770 processor from the \textit{Ivy Bridge} generation. To avoid wasting too much time with frequency switches, a core will keep running at a reduced frequency for a while after the last \gls{AVX} instruction has been executed.

\emph{ChaCha20} \cite{bernstein2008chacha} is a stream cipher algorithm for symmetric encryption presented by Daniel J. Bernstein in 2008 that, in the recent years, quickly gained traction as various implementations have been developed and employed in wide-spread commercial products. Google has added support for this algorithm in their Android operating system as well as the Chrome web browser in 2014 \cite{googlechacha20} and, as of June 2016, a cipher suite based on ChaCha20 has become a proposed standard for use in the \gls{TLS} protocol that is commonly used to encrypt internet traffic \cite{rfc7905}. Given the rising adoption of Bernstein's algorithm, it became desirable to create implementations optimized for speed and energy efficiency. \citeauthor{goll2014vectorization} \cite{goll2014vectorization} have presented an \gls{AVX2} implementation of ChaCha20 using \SI{256}{\bit} vectors that provides about doubled performance on an Intel \textit{Haswell} processor compared to an implementation using \gls{SSE} with \SI{128}{\bit} vectors. However, in practice, engineers from Cloudflare \cite{cloudflareinteldangers} have benchmarked the \emph{nginx} web server with a version of the \emph{OpenSSL} cryptographic library that contains an implementation of ChaCha20 with support for \gls{AVX2} and \gls{AVX-512} on an Intel Xeon Silver 4116 processor and found that nginx's throughput is reduced by \SI{10.6}{\percent} compared to when it runs with a variant of OpenSSL without \gls{AVX}. These findings were confirmed by \citeauthor{gottschlag19sfma} \cite{gottschlag19sfma} who measured a \SI{11.4}{\percent} decrease in throughput on an Intel Xeon Gold 6130 processor when comparing nginx with an \gls{AVX-512}-capable implementation of OpenSSL versus an \gls{SSE}4 one.

While at first glance it may seem strange that increased vectorization with \gls{AVX} reduces performance, this behavior is easily explained by the description of Intel's \gls{AVX} implementation above: nginx in combination with an \gls{AVX}-capable build of the OpenSSL library is an example of what we call a \emph{heterogeneous workload} -- a program where only certain parts benefit from vector execution, whereas the rest solely uses scalar instructions. Encryption only takes up a fraction of a web server's total processing time, so only this particular fraction is accelerated through \gls{AVX}. Now, the performance reduction observed when enabling \gls{AVX} originates from the fact that the other part of the program is slowed down due to the attained frequency reduction after \gls{AVX} instructions were executed. This poses a problem for the use of \gls{AVX} in real-world software: only programs that can use vectorization for large parts or nearly all of their code may see benefits, whereas there is a large hazard for developers of software with heterogeneous workloads to cause harm to their program's performance.

\section{Methodology}
\label{sec:background:methodology}

\section{Dynamic Voltage and Frequency Scaling}
\label{sec:background:dvfs}

\citeauthor{mittal2014survey} \cite{mittal2014survey} defines \textit{\acrlong{DVFS}} ({\acrshort{DVFS}\glsunset{DVFS}) as a technique \enquote{for altering the voltage and/or frequency of a computing system based on performance and power requirements.} The required electrical power $P$ for switching a \gls{CMOS} gatter can be characterized as $P=\frac{1}{2} \times C \times V^2 \times f$, where $C$ is the circuit's electrical capacitance, $V$ is the voltage and $f$ is the switching frequency \cite{Hennessy:2017:CAS:3207796}. Looking at the formula where power increases linear in frequency and quadratic in voltage, it becomes clear that the power consumption of a processor can be regulated by controlling these two parameters. Therefore, the idea behind \gls{DVFS} is to have a microprocessor run at high frequencies when system load demands for high performance and at lower frequencies when the system is idling to save energy -- the voltage is set according to what is required to maintain stable execution (i.e., all transistors properly switch within a single clock cycle) at the respective frequencies.

Modern Intel processors have a \gls{DVFS} implementation called \emph{Enhanced Intel SpeedStep Technology} (EIST) \cite{intelsdmsysprogguide}. Using EIST, the operating system may select a \glspl{P-state} for each core -- these \emph{performance states} govern a core's frequency and its voltage. On current-generation processors, \glspl{P-state} simply represent numeric multipliers of the chip's bus clock.

Further, the \textit{Skylake} microarchitecture generation introduced in 2015 was the first to support \emph{Intel Speed Shift Technology} \cite{intelsykalekannouncement}, an implementation of the \emph{Collaborative Processor Performance Control} (CPPC) interface defined by the \gls{ACPI} standard \cite{acpispec}. Outside of public marketing, Speed Shift is also called \emph{Hardware-Controlled P-States} (HWP) in Intel's technical documents \cite{intelsdmsysprogguide}. As the name implies, when using HWP, control over the processor's \glspl{P-state} is transferred from the operating system to the hardware itself. Precisely, with \gls{HWP}, a \textit{\acrlong{PCU}} (\acrshort{PCU}\glsunset{PCU}) in the processor constantly monitors load on different parts of the chip as well as power consumption and accordingly assigns voltages and frequencies to the different units within the chip. Contrary to previous possibilities with EIST, the operating system is merely left with the ability to hint the processor about the desired minimum and maximum performance as well as the user's preferences for energy efficiency.

Notably, starting with the \textit{Haswell} microarchitecture (a predecessor of \textit{Skylake}), Intel implemented physical measurement of the power consumption in their processors, whereas previous generations only relied on statistical models. \citeauthor{schuchart2016shift} \cite{schuchart2016shift} have shown these measurements to be very precise and in turn, the \gls{PCU} of these chips is capable of limiting a processor's power consumption nearly exactly at its specified \gls{TDP}. However, as the authors have shown, this introduces deviations in the performance of different chips of the same model up to \SI{5}{\percent} compared to the average due to production fluctuations where some chips require more or less power than others. It is plausible that this variance may be carried over to the results of our analysis when executed on different chips.

In this thesis, we will conduct the \gls{AVX} reclocking analysis with \gls{HWP} enabled as this would be the usual case for real-world systems equipped with current Intel processors. For our software reimplementation, however, we are going to disable \gls{HWP} and make use of the legacy EIST software interface as we need to be able to control the processor's clock speed via means of the operating system.

\section{Related Work}

